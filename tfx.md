# TFX : A TensorFlow-Based Production-Scale Machine Learning Platform

[paper link](http://stevenwhang.com/tfx_paper.pdf)

## Summary

- TensorFlow ベースの機械学習基盤である TFX の使い方の解説と実際のデプロイまでの流れを説明している

- 著者らは Google Play ストアの担当チームであり、その業務経験から機械学習運用の経験則からの知見も示している

- TFX を構成する各モジュールは、機械学習活用のステージ順に data analysis, data transformation,
    data validation, trainer, model analysis, serving で、それぞれどのような役割があるかを紹介

## 機械学習の運用フレームワークに必要なもの

著者らは機械学習の運用フレームワークとして、以下のような要件があるとよいと考えている。

1. **多くの学習タスクを単一プラットフォームで** (One ML platform for many learning tasks): 多くの異なるタスクを規格化できるように。Tensorflow は、線形学習、 DL, それらの混合、決定木ベースのアルゴリズム、系列学習、など多くのアルゴリズムをカバーしている。

2. **継続的な学習とリリース** (Continuous training and serving): One-shot ではなく日々反復して訓練できるような機械学習プラットフォームであること。共通の1つの設定で全てのコンポネントを記述し、必要ならば共有もできる。コンポネントを規格化しているのでデバッグや状態管理もまとめて行える。

3. **人間参加型** (Human-in-the-loop): エンジニアが簡単にデプロイできるようなインターフェイス、ユーザーの理解を助けデータとモデルを分析する助けになること。機械学習のデプロイの複雑なところを取り扱えカプセル化できればエンジニアもデータサイエンティストもより実用的なモデルを作成するタスクに専念できる。

4. **プロダクトレベルの信頼性とスケーラビリティ** (Production-level reliability and scalability):
    入力データ、ソフトウェア、ユーザー設定などの変化に柔軟であること、稼働システムの大量データやトラフィックの増加に対してもスケールすること。

## Data Analysis

データを取り込んで各変数の記述統計(平均や分散、頻出ラベル上位K個、など)を計算したり度数表やヒストグラムを描画したりするほか、2変数間の関係、相関係数を計算したり散布図を描画したりするコンポネント。データの概形を捉える、品質管理、などの用途があります。データが膨大になると、このような処理は難しくなるが、TFX では近似計算アルゴリズムを提供します。

## Data Transformation

この工程ではとてもエラーが出やすい。単なるエラーではなく、エラーとして検出しにくい品質の悪化も存在するので厄介。TFX のこのコンポネントは、押し付けがましくない程度のアラートや、どう対応すべきかのヒントを与えてくれる。 例えば,

- feature-to-integer mapping (単語と整数の一対一変換)

- 整数ID値の sparse categorical featuring. sparse化はユニーク値が1\~100B
    くらいあるような特徴量に対して時間・空間計算量の節約になる。

など。

特に重大な問題は、訓練データと本番データとで変換ロジックを一致させる必要があること。訓練データとは違うやり方で入力を変換させたような特徴量はモデルの性能を損ねる。TFX はこのような問題にも対処できる。

## Data Validation

DA の後で、どのようにデータをテストすべきか、データは健全か、それとも問題があるか、それはユーザーに通知すべきか、ということを記述したスキーマを用意し動作させるコンポーネント。例えば以下のような項目をチェックできる。

- データに存在することが期待されている特徴量

- 期待されている各特徴量の型

- 期待されている各特徴量の性質、最小カウント、例数の比率、などなど

- 期待される観測ごとの特徴の性質。最大値、最小値など

## Model Training

すでに書いたように TF には多彩な学習アルゴリズムの訓練機能があり、アルゴリズムの変更も簡単にできます。継続的に訓練をやり直すような運用は、典型的な機械学習の事例だが、実際に膨大なデータで性能を維持しつつ続けるのは時間・リソースともに要求され難しい。Google でもそのような課題に直面することが何度かあった。たとえば Google Play ストアには毎日数千もの新たなアプリが導入されている。

性能が要求水準になるように訓練するには、膨大なデータセットで数時間、ときには数日かけて計算する必要があり、モデルの性能と、「モデルの鮮度」はトレードオフの関係にあった。 TFX では、*warm-starting* というテクニックでこの問題に対処した。warm-starting は**転移学習** (transfer learning) に着想を得たもの。転移学習の一般的なアプローチでは、基本データセットで基本となるニューラルネットワークを学習する。次に、基本ネットワークから「汎化パラメータ」を得て予測対象のデータに使うネットワークの初期化に使い、最後に対象データセットに対するネットワークを学習させる。TFX ではこのような機能も単一の高級APIを介して容易に活用できる。

### 高級APIについて

TFX を高級APIにしている概念に `FeatureColumns` と `Estimator`
がある。前者はどの特徴量を入力に使っているのか一望してわかるようにしてくれる。後者はモデルの訓練と評価を行うクラスである。

## モデルの評価と検証 (Model Analysis)

### 「良い」モデルとは何か定義する

機械学習のモデルは複雑な処理をし、入力データも膨大だったり予期しないものだったりする。 よって、モデルの**精度の質**
(prediction quality) と**リリース安全性** (safe to serve) の両方で評価する必要がある。

リリース安全性とは問題のある or 予期しない入力を受け取ったり出力したりしたときにエラーを出したりクラッシュしたり大量のリソースを要したりしないこと。具体例として、リリースしたもので使っている機械学習ライブラリより新しいバージョンのものを開発時に使っており、新しく開発したモデルをリリースしたらエラーが発生した、とか。

精度の質の評価では、入力から予測までのプロセスを1つの系として見たとき、精度がしきい値を超えているかで評価する。このしきい値は、たとえば現行モデルの予測精度など。

常にモデルを学習し変更し続けるやり方で問題となるのは、全ての潜在的エラーを把握できないことと、「期待どおりの変化」と「期待していない変化」を切り分けることが難しいこと。訓練データが毎回かわるので、当てはまりの指標も変わる。つまり、保守的になりすぎて細かな変化のたびにアラートを出した結果、めんどくさくなってアラートを完全に無視するようになるか、逆に緩くしすぎて多くの期待していない変化を見落とすか、というトレードオフ。
著者らの経験から言うと、多くのバグは指標に劇的な変化をもたらすので、ゆるい基準でも検知できる。しかし、これは無数の微小なバグが問題にされなかっただけ、という選択バイアスでしかないともいえる。

### スライシング

著者らのチームでは、訓練データから一部を抜き出したものを**スライス** (slice) と呼んでいる。著者らは特に米国内のデータを対象としたモデルの精度を気にしているので、しばしば米国のスライスデータだけでモデルの性能を評価することがあります。データセット全体となると膨大であり、全体で計算した指標では局所的なあてはまりを反映しない可能性があるため。そのため、TFMA のスライシングは、プロダクトチームがモデルの精度を向上させるのに役立ったり、全体の精度改善のために重要なスライスでの精度を犠牲にするようなことを回避できる。

### モデルのデプロイ

TensorFlow Serving (TFS) を使う。これは、完全に、かつカスタマイズ可能なようにデプロイできるようにするため、プロダクトレベルの機械学習モデルをサーバーシステムにデプロイできるようなフレームワークである。通常のデプロイに必要なお決まりのコード
(boilerplate code) を書く手間を削減してくれる。

TF Serving の文脈では、 マルチテナント性 (Multitenancy) とは、1つのサーバーインスタンスで複数の機械学習モデルを同時に動かすことを意味する。毎秒膨大な数のリクエストさばくと同時に、モデルを読み込むプロセスも処理しなければならない。両者の干渉をなくし、独立性を向上するため、モデル読み込み処理を独立した専用スレッドプールとして設定できる機能を追加した。

TF は共通のデータ形式を使用するという特徴がある。このおかげで、組織内でデータ、モデル、ツール、視覚化、最適化その他のテクニックを共有しやすくしている。一方で、形式を共通化することは、特定の目的に最適化したものに対してデータサイズや読み込み速度についてトレードオフの関係が発生する。ニューラルネットワーク以外のモデルは、CPU集約的というよりデータ集約的で、データのI/Oがボトルネックになりやすい。この問題を解決するため、複数のパーサー設定で目的特化されたプロトコルバッファーパーサを用意できるようにした。

## ケーススタディ

Google Play ストアにデプロイした推薦システムの例が紹介されている。ユーザが役に立つアプリを発見できるようにするというのが目的で、ストアのアプリページにアクセスしたとき、関連するアプリを表示させる。ユーザーがアクセスしたときにそのユーザーの情報とアプリの情報を送り
(クエリ)、推薦システムはいくつかのアプリのリストを返し、ランキングシステムがアプリごとにスコアを計算する。

典型的な場合では訓練データは数千億件のデータで、1件1件にユーザーの情報やアプリの評価レートなどの特徴量が含まれる。これを学習し厳密なモデルの評価をパスすると、モデルは TFS でデータセンターにデプロイされる。ここでは毎秒数千件のクエリが送られ、数百ミリ秒単位でのレイテンシが要求される。プロダクトレベルのモデルも実験段階のモデルも、鮮度の維持のため日々学習が行われる。これをレイテンシの低下なく行う必要がある。従来のフレームワークから TFX に移行したことで、学習に必要な計算量の削減を始め多くの恩恵があった。
